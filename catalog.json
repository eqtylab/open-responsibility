[
  {
    "frameworkId": "dasf",
    "frameworkName": "Databricks AI Security Framework (DASF)",
    "description": "The Databricks AI Security Framework (DASF) is a comprehensive guide developed by the Databricks Security team to help organizations understand and mitigate the evolving security risks associated with the widespread integration of artificial intelligence (AI) systems. Unlike approaches that focus solely on securing models or endpoints, the DASF adopts a holistic strategy to address cyber risks across all components of an AI system. The framework is designed to facilitate collaboration between business, IT, data, AI, and security teams throughout the AI lifecycle. It provides actionable defensive control recommendations that can be updated as new risks emerge and additional controls become available. The DASF walks readers through the 12 foundational components of a generic data-centric AI system, detailing 55 identified technical security risks and dedicated controls to mitigate those risks. It also includes a guide on how to manage and deploy AI models safely and securely using the Databricks Data Intelligence Platform. The framework aims to be a valuable resource for security teams, ML practitioners, and governance officers to gain insights into AI system security, apply security engineering principles to ML, and access a detailed guide for understanding the security and compliance of specific ML systems.",
    "stages": [
      "Data Operations",
      "Model Operations",
      "Model Deployment and Serving",
      "Operations and Platform"
    ],
    "version": "1.0",
    "totalRisks": 55,
    "totalControls": 54,
    "path": "./frameworks/dasf"
  },
  {
    "frameworkId": "aibam",
    "frameworkName": "AI Bias Assessment and Mitigation Framework",
    "description": "The AI Bias Assessment and Mitigation Framework is a comprehensive approach for identifying, assessing, and mitigating bias throughout the AI development lifecycle. It provides a structured methodology to address bias-related risks across various stages and components of an AI system. The framework emphasizes the importance of conducting regular bias assessments, implementing bias mitigation strategies, and monitoring AI systems for emergent biases. It includes a set of controls that cover data collection and preprocessing, model development and training, model evaluation and testing, and deployment and monitoring. The framework aims to help organizations develop fair, unbiased, and trustworthy AI systems by providing guidance on bias assessment methodologies, mitigation techniques, and ongoing monitoring practices. It is designed to be a valuable resource for AI practitioners, risk managers, and compliance officers to understand and address the challenges of bias in AI systems.",
    "stages": [
      "Data Collection and Preprocessing",
      "Model Development and Training",
      "Model Evaluation and Testing",
      "Deployment and Monitoring"
    ],
    "version": "1.0",
    "totalRisks": 7,
    "totalControls": 5,
    "path": "./frameworks/sample"
  }
]
